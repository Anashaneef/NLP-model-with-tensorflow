# -*- coding: utf-8 -*-
"""proyek1_NLP_dengan_tensorflow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GBcSebnlD46AUFJpYqAlaX5B7X4xOW4_

Nama = Anas Fikri Hanif\
SIB ID = M183X0321

**Import Library**
"""

import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

"""**Menyiapkan Dataset**"""

df = pd.read_csv('vgsales.csv')

# membuang kolom yang tidak perlu
df = df.drop(columns=['Rank', 'Platform', 'Year', 'Publisher', 'NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales'])

df.head(20)

# melakukan one-hot-encoding untuk mengatasi label bertipe categorical
category = pd.get_dummies(df.Genre)
df_baru = pd.concat([df, category], axis=1)
df_baru = df_baru.drop(columns=['Genre'])
df_baru

nama = df_baru['Name'].values
label = df_baru[['Action', 'Adventure', 'Fighting', 'Misc', 'Platform', 'Puzzle', 'Racing', 'Role-Playing', 'Shooter', 'Simulation', 'Sports', 'Strategy']].values

"""**Splitting Data Menjadi Training dan Testing**"""

# alokasi data testing 20%

nama_latih, nama_test, label_latih, label_test = train_test_split(nama, label, test_size=0.2)

"""**Tokenizer dan Sequence**"""

tokenizer = Tokenizer(num_words=5000, oov_token='x')
tokenizer.fit_on_texts(nama_latih)
tokenizer.fit_on_texts(nama_test)

sekuens_latih = tokenizer.texts_to_sequences(nama_latih)
sekuens_test = tokenizer.texts_to_sequences(nama_test)

padded_latih = pad_sequences(sekuens_latih)
padded_test = pad_sequences(sekuens_test)

"""**Pembuatan Model**"""

model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=5000, output_dim=16),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(12, activation='sigmoid')
])
model.compile(optimizer='adam',
              loss = 'categorical_crossentropy',
              metrics = ['accuracy'])

"""**Pembuatan Callbacks**"""

class myCallbacks(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.96):
      print('\nAkurasi telah mencapai 91% !')
      self.model.stop_training = True
callbacks = myCallbacks()

"""**Fitting Model**"""

num_epoch = 50
history = model.fit(
    padded_latih,
    label_latih,
    epochs = num_epoch,
    validation_data = (padded_test, label_test),
    verbose = 2,
    callbacks = [callbacks])

"""**Plot Accuracy dan Loss saat Testing dan Training**"""

# plot accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Akurasi Model')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['train', 'test'], loc = 'upper left')
plt.show()

# plot loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss Model')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['train', 'test'], loc = 'upper left')
plt.show()